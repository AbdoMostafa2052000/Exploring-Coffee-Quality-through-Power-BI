{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d036bfcd",
   "metadata": {},
   "source": [
    "# Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0acb52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O \n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt # create graphs\n",
    "from dateutil import parser #parsing dates\n",
    "import seaborn as sns # create graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7ea71b",
   "metadata": {},
   "source": [
    "# Load data\n",
    "data_link: https://www.kaggle.com/datasets/volpatto/coffee-quality-database-from-cqi?select=merged_data_cleaned.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60060fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Species</th>\n",
       "      <th>Owner</th>\n",
       "      <th>Country.of.Origin</th>\n",
       "      <th>Farm.Name</th>\n",
       "      <th>Lot.Number</th>\n",
       "      <th>Mill</th>\n",
       "      <th>ICO.Number</th>\n",
       "      <th>Company</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>...</th>\n",
       "      <th>Color</th>\n",
       "      <th>Category.Two.Defects</th>\n",
       "      <th>Expiration</th>\n",
       "      <th>Certification.Body</th>\n",
       "      <th>Certification.Address</th>\n",
       "      <th>Certification.Contact</th>\n",
       "      <th>unit_of_measurement</th>\n",
       "      <th>altitude_low_meters</th>\n",
       "      <th>altitude_high_meters</th>\n",
       "      <th>altitude_mean_meters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>2014/2015</td>\n",
       "      <td>metad agricultural developmet plc</td>\n",
       "      <td>1950-2200</td>\n",
       "      <td>...</td>\n",
       "      <td>Green</td>\n",
       "      <td>0</td>\n",
       "      <td>April 3rd, 2016</td>\n",
       "      <td>METAD Agricultural Development plc</td>\n",
       "      <td>309fcf77415a3661ae83e027f7e5f05dad786e44</td>\n",
       "      <td>19fef5a731de2db57d16da10287413f5f99bc2dd</td>\n",
       "      <td>m</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2075.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>2014/2015</td>\n",
       "      <td>metad agricultural developmet plc</td>\n",
       "      <td>1950-2200</td>\n",
       "      <td>...</td>\n",
       "      <td>Green</td>\n",
       "      <td>1</td>\n",
       "      <td>April 3rd, 2016</td>\n",
       "      <td>METAD Agricultural Development plc</td>\n",
       "      <td>309fcf77415a3661ae83e027f7e5f05dad786e44</td>\n",
       "      <td>19fef5a731de2db57d16da10287413f5f99bc2dd</td>\n",
       "      <td>m</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2075.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>grounds for health admin</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>san marcos barrancas \"san cristobal cuch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600 - 1800 m</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>May 31st, 2011</td>\n",
       "      <td>Specialty Coffee Association</td>\n",
       "      <td>36d0d00a3724338ba7937c52a378d085f2172daa</td>\n",
       "      <td>0878a7d4b9d35ddbf0fe2ce69a2062cceb45a660</td>\n",
       "      <td>m</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>yidnekachew dabessa</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>yidnekachew dabessa coffee plantation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wolensu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yidnekachew debessa coffee plantation</td>\n",
       "      <td>1800-2200</td>\n",
       "      <td>...</td>\n",
       "      <td>Green</td>\n",
       "      <td>2</td>\n",
       "      <td>March 25th, 2016</td>\n",
       "      <td>METAD Agricultural Development plc</td>\n",
       "      <td>309fcf77415a3661ae83e027f7e5f05dad786e44</td>\n",
       "      <td>19fef5a731de2db57d16da10287413f5f99bc2dd</td>\n",
       "      <td>m</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>2014/2015</td>\n",
       "      <td>metad agricultural developmet plc</td>\n",
       "      <td>1950-2200</td>\n",
       "      <td>...</td>\n",
       "      <td>Green</td>\n",
       "      <td>2</td>\n",
       "      <td>April 3rd, 2016</td>\n",
       "      <td>METAD Agricultural Development plc</td>\n",
       "      <td>309fcf77415a3661ae83e027f7e5f05dad786e44</td>\n",
       "      <td>19fef5a731de2db57d16da10287413f5f99bc2dd</td>\n",
       "      <td>m</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2075.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Species                     Owner Country.of.Origin  \\\n",
       "0           0  Arabica                 metad plc          Ethiopia   \n",
       "1           1  Arabica                 metad plc          Ethiopia   \n",
       "2           2  Arabica  grounds for health admin         Guatemala   \n",
       "3           3  Arabica       yidnekachew dabessa          Ethiopia   \n",
       "4           4  Arabica                 metad plc          Ethiopia   \n",
       "\n",
       "                                  Farm.Name Lot.Number       Mill ICO.Number  \\\n",
       "0                                 metad plc        NaN  metad plc  2014/2015   \n",
       "1                                 metad plc        NaN  metad plc  2014/2015   \n",
       "2  san marcos barrancas \"san cristobal cuch        NaN        NaN        NaN   \n",
       "3     yidnekachew dabessa coffee plantation        NaN    wolensu        NaN   \n",
       "4                                 metad plc        NaN  metad plc  2014/2015   \n",
       "\n",
       "                                 Company       Altitude  ...  Color  \\\n",
       "0      metad agricultural developmet plc      1950-2200  ...  Green   \n",
       "1      metad agricultural developmet plc      1950-2200  ...  Green   \n",
       "2                                    NaN  1600 - 1800 m  ...    NaN   \n",
       "3  yidnekachew debessa coffee plantation      1800-2200  ...  Green   \n",
       "4      metad agricultural developmet plc      1950-2200  ...  Green   \n",
       "\n",
       "  Category.Two.Defects        Expiration                  Certification.Body  \\\n",
       "0                    0   April 3rd, 2016  METAD Agricultural Development plc   \n",
       "1                    1   April 3rd, 2016  METAD Agricultural Development plc   \n",
       "2                    0    May 31st, 2011        Specialty Coffee Association   \n",
       "3                    2  March 25th, 2016  METAD Agricultural Development plc   \n",
       "4                    2   April 3rd, 2016  METAD Agricultural Development plc   \n",
       "\n",
       "                      Certification.Address  \\\n",
       "0  309fcf77415a3661ae83e027f7e5f05dad786e44   \n",
       "1  309fcf77415a3661ae83e027f7e5f05dad786e44   \n",
       "2  36d0d00a3724338ba7937c52a378d085f2172daa   \n",
       "3  309fcf77415a3661ae83e027f7e5f05dad786e44   \n",
       "4  309fcf77415a3661ae83e027f7e5f05dad786e44   \n",
       "\n",
       "                      Certification.Contact unit_of_measurement  \\\n",
       "0  19fef5a731de2db57d16da10287413f5f99bc2dd                   m   \n",
       "1  19fef5a731de2db57d16da10287413f5f99bc2dd                   m   \n",
       "2  0878a7d4b9d35ddbf0fe2ce69a2062cceb45a660                   m   \n",
       "3  19fef5a731de2db57d16da10287413f5f99bc2dd                   m   \n",
       "4  19fef5a731de2db57d16da10287413f5f99bc2dd                   m   \n",
       "\n",
       "  altitude_low_meters altitude_high_meters altitude_mean_meters  \n",
       "0              1950.0               2200.0               2075.0  \n",
       "1              1950.0               2200.0               2075.0  \n",
       "2              1600.0               1800.0               1700.0  \n",
       "3              1800.0               2200.0               2000.0  \n",
       "4              1950.0               2200.0               2075.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file into a pandas DataFrame and store it in the variable 'df'.\n",
    "# The file path provided should point to the location of the CSV file on your system.\n",
    "df = pd.read_csv(\"merged_data_cleaned.csv\")\n",
    "\n",
    "# Display the first few rows of the DataFrame to quickly inspect the data.\n",
    "# It helps to get a quick overview of the data structure and contents.\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6298e1",
   "metadata": {},
   "source": [
    "# Basic exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63975d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1339\n",
      "Number of columns: 44\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the dimensions of the DataFrame (number of rows, number of columns).\n",
    "shape = df.shape\n",
    "\n",
    "# The first element of the tuple shape represents the number of rows, while the second element represents the number of columns.\n",
    "# Print the dimensions of the DataFrame.\n",
    "print(\"Number of rows:\", shape[0])\n",
    "print(\"Number of columns:\", shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad38f09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Species', 'Owner', 'Country.of.Origin', 'Farm.Name',\n",
      "       'Lot.Number', 'Mill', 'ICO.Number', 'Company', 'Altitude', 'Region',\n",
      "       'Producer', 'Number.of.Bags', 'Bag.Weight', 'In.Country.Partner',\n",
      "       'Harvest.Year', 'Grading.Date', 'Owner.1', 'Variety',\n",
      "       'Processing.Method', 'Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body',\n",
      "       'Balance', 'Uniformity', 'Clean.Cup', 'Sweetness', 'Cupper.Points',\n",
      "       'Total.Cup.Points', 'Moisture', 'Category.One.Defects', 'Quakers',\n",
      "       'Color', 'Category.Two.Defects', 'Expiration', 'Certification.Body',\n",
      "       'Certification.Address', 'Certification.Contact', 'unit_of_measurement',\n",
      "       'altitude_low_meters', 'altitude_high_meters', 'altitude_mean_meters'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the column names (labels) of the DataFrame 'df'.\n",
    "columns = df.columns\n",
    "\n",
    "# Print the column names of the DataFrame.\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "171c2c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1339 entries, 0 to 1338\n",
      "Data columns (total 44 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             1339 non-null   int64  \n",
      " 1   Species                1339 non-null   object \n",
      " 2   Owner                  1332 non-null   object \n",
      " 3   Country.of.Origin      1338 non-null   object \n",
      " 4   Farm.Name              980 non-null    object \n",
      " 5   Lot.Number             276 non-null    object \n",
      " 6   Mill                   1021 non-null   object \n",
      " 7   ICO.Number             1182 non-null   object \n",
      " 8   Company                1130 non-null   object \n",
      " 9   Altitude               1113 non-null   object \n",
      " 10  Region                 1280 non-null   object \n",
      " 11  Producer               1107 non-null   object \n",
      " 12  Number.of.Bags         1339 non-null   int64  \n",
      " 13  Bag.Weight             1339 non-null   object \n",
      " 14  In.Country.Partner     1339 non-null   object \n",
      " 15  Harvest.Year           1292 non-null   object \n",
      " 16  Grading.Date           1339 non-null   object \n",
      " 17  Owner.1                1332 non-null   object \n",
      " 18  Variety                1113 non-null   object \n",
      " 19  Processing.Method      1169 non-null   object \n",
      " 20  Aroma                  1339 non-null   float64\n",
      " 21  Flavor                 1339 non-null   float64\n",
      " 22  Aftertaste             1339 non-null   float64\n",
      " 23  Acidity                1339 non-null   float64\n",
      " 24  Body                   1339 non-null   float64\n",
      " 25  Balance                1339 non-null   float64\n",
      " 26  Uniformity             1339 non-null   float64\n",
      " 27  Clean.Cup              1339 non-null   float64\n",
      " 28  Sweetness              1339 non-null   float64\n",
      " 29  Cupper.Points          1339 non-null   float64\n",
      " 30  Total.Cup.Points       1339 non-null   float64\n",
      " 31  Moisture               1339 non-null   float64\n",
      " 32  Category.One.Defects   1339 non-null   int64  \n",
      " 33  Quakers                1338 non-null   float64\n",
      " 34  Color                  1121 non-null   object \n",
      " 35  Category.Two.Defects   1339 non-null   int64  \n",
      " 36  Expiration             1339 non-null   object \n",
      " 37  Certification.Body     1339 non-null   object \n",
      " 38  Certification.Address  1339 non-null   object \n",
      " 39  Certification.Contact  1339 non-null   object \n",
      " 40  unit_of_measurement    1339 non-null   object \n",
      " 41  altitude_low_meters    1109 non-null   float64\n",
      " 42  altitude_high_meters   1109 non-null   float64\n",
      " 43  altitude_mean_meters   1109 non-null   float64\n",
      "dtypes: float64(16), int64(4), object(24)\n",
      "memory usage: 460.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display concise summary information about the DataFrame 'df'.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f2e296f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                0.000000\n",
      "Species                   0.000000\n",
      "Owner                     0.522778\n",
      "Country.of.Origin         0.074683\n",
      "Farm.Name                26.811053\n",
      "Lot.Number               79.387603\n",
      "Mill                     23.749066\n",
      "ICO.Number               11.725168\n",
      "Company                  15.608663\n",
      "Altitude                 16.878267\n",
      "Region                    4.406273\n",
      "Producer                 17.326363\n",
      "Number.of.Bags            0.000000\n",
      "Bag.Weight                0.000000\n",
      "In.Country.Partner        0.000000\n",
      "Harvest.Year              3.510082\n",
      "Grading.Date              0.000000\n",
      "Owner.1                   0.522778\n",
      "Variety                  16.878267\n",
      "Processing.Method        12.696042\n",
      "Aroma                     0.000000\n",
      "Flavor                    0.000000\n",
      "Aftertaste                0.000000\n",
      "Acidity                   0.000000\n",
      "Body                      0.000000\n",
      "Balance                   0.000000\n",
      "Uniformity                0.000000\n",
      "Clean.Cup                 0.000000\n",
      "Sweetness                 0.000000\n",
      "Cupper.Points             0.000000\n",
      "Total.Cup.Points          0.000000\n",
      "Moisture                  0.000000\n",
      "Category.One.Defects      0.000000\n",
      "Quakers                   0.074683\n",
      "Color                    16.280807\n",
      "Category.Two.Defects      0.000000\n",
      "Expiration                0.000000\n",
      "Certification.Body        0.000000\n",
      "Certification.Address     0.000000\n",
      "Certification.Contact     0.000000\n",
      "unit_of_measurement       0.000000\n",
      "altitude_low_meters      17.176998\n",
      "altitude_high_meters     17.176998\n",
      "altitude_mean_meters     17.176998\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of missing values for each column using the 'isnull()' method.\n",
    "missing_values_count = df.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values for each column by dividing the number of missing values by the total number of rows in the DataFrame.\n",
    "# missing_values_count is multiplied by 100 to convert it to a percentage.\n",
    "percent_missing = missing_values_count * 100 / len(df)\n",
    "\n",
    "# Display the percentage of missing values for each column.\n",
    "print(percent_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e88f824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabica    1311\n",
      "Robusta      28\n",
      "Name: Species, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Access the 'Species' column of the DataFrame 'df' and retrieve the counts of each unique value to see categories of coffee Speciesin this dataset.\n",
    "# The 'value_counts()' method counts the occurrences of each unique value in the 'Species' column and returns a Series.\n",
    "species_counts = df['Species'].value_counts()\n",
    "\n",
    "# Print the counts of each unique value in the 'Species' column, displaying them in descending order.\n",
    "print(species_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1eff4c",
   "metadata": {},
   "source": [
    "# Understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff6d604",
   "metadata": {},
   "source": [
    "The Arabica coffee data contains 44 columns and 1339 rows.\n",
    "\n",
    "Of the 44 columns, we are only interested in some of these columns which are Unnamed(representing id), Country.of.Origin, Producer, Harvest.Year, Grading.Date, Processing.Method, Aroma, Flavor, Aftertaste, Acidity, Body, Balance, Cupper.Points, Total.Cup.Points, Moisture, Category.One.Defects, Color, Category.Two.Defects, Expiration.\n",
    "\n",
    "Since the dataset is relatively small with few rows, it's crucial to handle any null values appropriately to maximize data utilization.\n",
    "\n",
    "This dataset consists of only two species (Arabica and Robusta), with one category having a significantly lower number of rows compared to the other.We'll focus on analyzing Arabica coffee samples with a higher number of rows to ensure reliable insights and statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71e29198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame 'df2' by dropping certain columns that are not needed for the analysis.\n",
    "# Columns such as 'Lot.Number', 'Mill', 'ICO.Number', etc., are dropped to focus only on relevant data for the analysis.\n",
    "df2 = df.drop(['Producer','Owner.1','Region','Owner','Company','Lot.Number', 'Mill', 'ICO.Number', 'Number.of.Bags', 'Bag.Weight', 'Variety', 'Farm.Name', 'Certification.Address', 'Certification.Contact', 'Certification.Body', 'In.Country.Partner', 'altitude_mean_meters', 'altitude_high_meters', 'altitude_low_meters', 'Species', 'Sweetness', 'Quakers', 'Clean.Cup', 'Uniformity'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93654644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'Defects' in DataFrame 'df2' by summing up the values from 'Category.One.Defects' and 'Category.Two.Defects'.\n",
    "# This new column represents the total number of defects for each entry, combining defects from two different categories.\n",
    "df2['Defects'] = df2['Category.One.Defects'] + df2['Category.Two.Defects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9df22be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns 'Category.One.Defects' and 'Category.Two.Defects' from DataFrame 'df2'.\n",
    "# These columns are dropped as they have been combined into a new column 'Defects'.\n",
    "df2.drop(['Category.One.Defects', 'Category.Two.Defects'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b8c5896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0              0.000000\n",
      "Country.of.Origin       0.074683\n",
      "Altitude               16.878267\n",
      "Harvest.Year            3.510082\n",
      "Grading.Date            0.000000\n",
      "Processing.Method      12.696042\n",
      "Aroma                   0.000000\n",
      "Flavor                  0.000000\n",
      "Aftertaste              0.000000\n",
      "Acidity                 0.000000\n",
      "Body                    0.000000\n",
      "Balance                 0.000000\n",
      "Cupper.Points           0.000000\n",
      "Total.Cup.Points        0.000000\n",
      "Moisture                0.000000\n",
      "Color                  16.280807\n",
      "Expiration              0.000000\n",
      "unit_of_measurement     0.000000\n",
      "Defects                 0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of missing values for each column using the 'isnull()' method.\n",
    "missing_values_count = df2.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values for each column by dividing the number of missing values by the total number of rows in the DataFrame.\n",
    "# missing_values_count is multiplied by 100 to convert it to a percentage.\n",
    "percent_missing = missing_values_count * 100 / len(df2)\n",
    "\n",
    "# Display the percentage of missing values for each column.\n",
    "print(percent_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f405d7",
   "metadata": {},
   "source": [
    "# Basic Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8b3316c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0 Country.of.Origin Altitude Harvest.Year     Grading.Date  \\\n",
      "1197        1197               NaN      NaN          NaN  March 1st, 2011   \n",
      "\n",
      "     Processing.Method  Aroma  Flavor  Aftertaste  Acidity  Body  Balance  \\\n",
      "1197               NaN   6.75    6.75        6.42     6.83  7.58      7.5   \n",
      "\n",
      "      Cupper.Points  Total.Cup.Points  Moisture Color           Expiration  \\\n",
      "1197           7.25             79.08       0.1   NaN  February 29th, 2012   \n",
      "\n",
      "     unit_of_measurement  Defects  \n",
      "1197                   m        3  \n"
     ]
    }
   ],
   "source": [
    "# Print rows where the 'Country.of.Origin' column is missing (null)\n",
    "# This helps to identify entries where the country of origin is not specified\n",
    "print(df2[pd.isnull(df2['Country.of.Origin'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f92da9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the 'Country.of.Origin' column with 'Colombia' based on the owner name\n",
    "# This assumes that if the country of origin is missing, it's should be as the owner's nationality\n",
    "df2['Country.of.Origin'].fillna('Colombia', inplace=True)\n",
    "\n",
    "# Normalize the 'Country.of.Origin' column to lower case\n",
    "df2['Country.of.Origin'] = df['Country.of.Origin'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "badf66a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the Country\n",
    "Country_of_Origin = {\n",
    "    \"united states (hawaii)\": \"hawaii, united states\",\n",
    "    \"united states (puerto rico)\": \"puerto rico, united states\",\n",
    "    \"cote d?ivoire\": \"cote divoire\"\n",
    "}\n",
    "\n",
    "# Define the fixCountry function\n",
    "def fixCountry(c):\n",
    "    if c == 'united states (hawaii)' or c == 'united states (puerto rico)':\n",
    "        return \"united states\"\n",
    "    elif c == \"cote d?ivoire\":\n",
    "        return 'cote divoire'\n",
    "    else:\n",
    "        return c\n",
    "\n",
    "# Applying the function to fix the values in the column\n",
    "df2['Country.of.Origin'] = df2['Country.of.Origin'].apply(fixCountry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d504b5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean altitude range values and calculate the mean altitude\n",
    "def clean_altitude_range(range_value):\n",
    "    if isinstance(range_value, str):\n",
    "        range_value = range_value.replace(\" \", \"\")  # Remove blank spaces\n",
    "        if '-' in range_value:\n",
    "            try:\n",
    "                start, end = range_value.split('-')\n",
    "                start = int(start)\n",
    "                end = int(end)\n",
    "                return (start + end) / 2  # Calculate the mean altitude for the range\n",
    "            except ValueError:\n",
    "                return np.nan  # Return NaN if the range cannot be parsed\n",
    "        else:\n",
    "            try:\n",
    "                return int(range_value)  # Convert single altitude value to int\n",
    "            except ValueError:\n",
    "                return np.nan  # Return NaN if the value cannot be parsed\n",
    "    else:\n",
    "        return range_value  # Return the original value if it's not a string\n",
    "\n",
    "\n",
    "# Apply the clean_altitude_range function to clean and calculate the mean altitude for each value in the \"Altitude\" column\n",
    "df2['Altitude'] = df2['Altitude'].apply(clean_altitude_range)\n",
    "\n",
    "# Fill missing values in the 'Altitude' column with the mean altitude\n",
    "df2['Altitude'].fillna(df2['Altitude'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6caffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null values in the 'Harvest.Year' column that cannot be reasonably estimated\n",
    "df2.dropna(subset=['Harvest.Year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e82403a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the 'Processing.Method' column with the most frequent value\n",
    "df2['Processing.Method'].fillna(df2['Processing.Method'].mode().iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bce83b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the 'Color' column with the most frequent value\n",
    "df2['Color'].fillna(df2['Color'].mode().iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b03aeaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo Mostafa\\AppData\\Local\\Temp\\ipykernel_1900\\3659457714.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df2['Harvest.Year'] = df2['Harvest.Year'].str.replace(r'[^0-9]', '')\n"
     ]
    }
   ],
   "source": [
    "# Set 'Harvest.Year' with the first year and remove any spaces\n",
    "df2['Harvest.Year'] = df2['Harvest.Year'].str.split('/').str[0].str.strip().str[:4]\n",
    "\n",
    "# Clean the 'Harvest.Year' column by removing any non-numeric characters\n",
    "df2['Harvest.Year'] = df2['Harvest.Year'].str.replace(r'[^0-9]', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d39632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More values cleaning\n",
    "harvest_year = list(df2['Harvest.Year'])\n",
    "new = []\n",
    "\n",
    "# Iterate through each element in the 'Harvest.Year' list\n",
    "for i in range(len(harvest_year)):\n",
    "    # Check if the length of the 'Harvest.Year' string at index i is less than 4\n",
    "    if len(harvest_year[i]) < 4:\n",
    "        # If the year has less than 4 digits, add \"20\" to the beginning of the year\n",
    "        new.append(str(2 * (10 ** (3 - len(harvest_year[i])))) + harvest_year[i])\n",
    "    else:\n",
    "        # If the year has 4 or more digits, keep it unchanged\n",
    "        new.append(harvest_year[i])\n",
    "\n",
    "# Update the 'Harvest.Year' column with the cleaned values\n",
    "df2['Harvest.Year'] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3df2a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Harvest.Year' and 'Expiration' columns to datetime objects using dateutil parser\n",
    "df2['Harvest.Year'] = df2['Harvest.Year'].apply(parser.parse)\n",
    "df2['Expiration'] = df2['Expiration'].apply(parser.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d571791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Subtracts the \"Harvest Year\" from the \"Expiration\" date and accesses the 'days' attribute of the resulting timedelta object\n",
    "# df2['Coffee Age'] = (df2['Expiration'] - df2['Harvest.Year']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e83a4a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve the indices of rows where the 'Coffee Age' is less than 0\n",
    "# # This filters the DataFrame to find rows where the difference between 'Expiration' and 'Harvest Year' is negative\n",
    "# index_of_negative_age = df2[df2['Coffee Age'] < 0].index\n",
    "\n",
    "# # Print or use the indices as needed\n",
    "# print(index_of_negative_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7af4d82f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Drop the rows where the 'Coffee Age' is less than 0 using their indices\n",
    "# df2.drop(df2[df2['Coffee Age'] < 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de1d0fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['April 4th, 2015', 'March 26th, 2015', 'September 3rd, 2013',\n",
       "       'September 17th, 2012', 'September 2nd, 2010', 'March 30th, 2015',\n",
       "       'March 27th, 2015', 'March 13th, 2015', 'May 31st, 2010',\n",
       "       'August 31st, 2010', 'June 16th, 2010', 'April 7th, 2016',\n",
       "       'March 25th, 2015', 'April 2nd, 2014', 'July 26th, 2012',\n",
       "       'December 3rd, 2011', 'June 26th, 2014', 'May 18th, 2017',\n",
       "       'May 18th, 2016', 'December 3rd, 2015', 'May 30th, 2014',\n",
       "       'April 6th, 2012', 'January 28th, 2011', 'June 17th, 2010',\n",
       "       'April 12th, 2012', 'January 4th, 2011', 'June 10th, 2015',\n",
       "       'January 29th, 2015', 'October 1st, 2014', 'March 20th, 2014',\n",
       "       'February 6th, 2014', 'February 13th, 2012', 'May 16th, 2016',\n",
       "       'June 30th, 2014', 'July 26th, 2013', 'October 9th, 2017',\n",
       "       'July 3rd, 2012', 'June 5th, 2012', 'June 23rd, 2017',\n",
       "       'January 22nd, 2014', 'October 25th, 2012', 'March 18th, 2013',\n",
       "       'January 12th, 2013', 'May 23rd, 2015', 'March 31st, 2015',\n",
       "       'February 26th, 2013', 'April 6th, 2016', 'May 1st, 2014',\n",
       "       'April 19th, 2013', 'March 12th, 2013', 'April 27th, 2016',\n",
       "       'April 8th, 2015', 'January 17th, 2014', 'November 26th, 2012',\n",
       "       'January 18th, 2012', 'August 9th, 2016', 'August 18th, 2015',\n",
       "       'October 7th, 2014', 'March 10th, 2014', 'March 16th, 2012',\n",
       "       'December 27th, 2010', 'July 24th, 2017', 'February 15th, 2017',\n",
       "       'January 30th, 2017', 'September 21st, 2016', 'May 7th, 2016',\n",
       "       'February 29th, 2012', 'April 6th, 2011', 'September 7th, 2010',\n",
       "       'November 25th, 2016', 'October 26th, 2015', 'June 9th, 2015',\n",
       "       'December 12th, 2014', 'December 11th, 2012', 'July 11th, 2012',\n",
       "       'December 23rd, 2011', 'August 26th, 2010', 'June 27th, 2016',\n",
       "       'June 2nd, 2015', 'April 25th, 2014', 'August 23rd, 2011',\n",
       "       'June 26th, 2017', 'November 24th, 2016', 'October 4th, 2016',\n",
       "       'June 1st, 2016', 'July 6th, 2015', 'March 5th, 2014',\n",
       "       'January 3rd, 2014', 'December 26th, 2013', 'December 20th, 2013',\n",
       "       'September 16th, 2012', 'July 17th, 2012', 'July 2nd, 2012',\n",
       "       'January 10th, 2017', 'December 28th, 2016', 'July 21st, 2014',\n",
       "       'May 29th, 2014', 'March 24th, 2014', 'December 6th, 2013',\n",
       "       'August 30th, 2013', 'July 17th, 2013', 'October 9th, 2012',\n",
       "       'November 28th, 2017', 'March 14th, 2017', 'June 5th, 2015',\n",
       "       'June 16th, 2014', 'June 6th, 2012', 'February 16th, 2012',\n",
       "       'March 23rd, 2011', 'March 22nd, 2011', 'March 23rd, 2017',\n",
       "       'January 25th, 2016', 'July 9th, 2014', 'July 10th, 2013',\n",
       "       'January 21st, 2013', 'August 3rd, 2017', 'May 11th, 2017',\n",
       "       'February 20th, 2017', 'April 4th, 2016', 'February 16th, 2016',\n",
       "       'April 29th, 2015', 'July 19th, 2013', 'July 27th, 2012',\n",
       "       'October 28th, 2011', 'April 30th, 2010', 'August 10th, 2017',\n",
       "       'November 2nd, 2016', 'August 5th, 2016', 'May 23rd, 2016',\n",
       "       'November 19th, 2015', 'August 21st, 2014', 'October 1st, 2013',\n",
       "       'September 11th, 2012', 'April 9th, 2012', 'April 2nd, 2012',\n",
       "       'June 1st, 2017', 'August 19th, 2016', 'June 23rd, 2016',\n",
       "       'August 3rd, 2015', 'April 24th, 2015', 'April 10th, 2015',\n",
       "       'October 15th, 2014', 'July 16th, 2014', 'November 7th, 2013',\n",
       "       'May 20th, 2013', 'May 9th, 2013', 'October 19th, 2012',\n",
       "       'March 26th, 2012', 'May 24th, 2017', 'November 9th, 2017',\n",
       "       'November 5th, 2014', 'January 24th, 2013', 'September 4th, 2012',\n",
       "       'August 17th, 2012', 'January 11th, 2018', 'June 5th, 2017',\n",
       "       'December 18th, 2014', 'August 8th, 2014', 'June 27th, 2014',\n",
       "       'May 27th, 2014', 'April 8th, 2014', 'January 2nd, 2014',\n",
       "       'June 21st, 2013', 'March 8th, 2013', 'June 21st, 2012',\n",
       "       'May 31st, 2012', 'August 16th, 2011', 'October 20th, 2017',\n",
       "       'July 3rd, 2017', 'October 18th, 2016', 'August 16th, 2016',\n",
       "       'February 11th, 2016', 'January 21st, 2016', 'November 7th, 2015',\n",
       "       'March 12th, 2015', 'November 23rd, 2014', 'June 30th, 2017',\n",
       "       'June 6th, 2016', 'February 23rd, 2016', 'October 8th, 2015',\n",
       "       'April 30th, 2015', 'October 16th, 2014', 'June 9th, 2014',\n",
       "       'May 22nd, 2014', 'October 4th, 2013', 'April 26th, 2013',\n",
       "       'December 21st, 2011', 'September 20th, 2011',\n",
       "       'September 28th, 2017', 'June 6th, 2017', 'November 27th, 2015',\n",
       "       'February 5th, 2014', 'January 24th, 2014', 'November 22nd, 2013',\n",
       "       'August 27th, 2013', 'May 2nd, 2013', 'September 27th, 2012',\n",
       "       'May 24th, 2012', 'April 20th, 2011', 'February 9th, 2011',\n",
       "       'September 1st, 2017', 'November 21st, 2014',\n",
       "       'February 27th, 2014', 'October 29th, 2013', 'August 16th, 2013',\n",
       "       'May 30th, 2013', 'November 22nd, 2012', 'August 23rd, 2012',\n",
       "       'July 9th, 2012', 'May 23rd, 2012', 'April 30th, 2012',\n",
       "       'July 5th, 2016', 'April 15th, 2016', 'May 12th, 2015',\n",
       "       'June 24th, 2014', 'March 13th, 2014', 'March 21st, 2014',\n",
       "       'August 31st, 2012', 'January 23rd, 2012', 'February 13th, 2017',\n",
       "       'March 16th, 2016', 'November 16th, 2015', 'September 14th, 2015',\n",
       "       'January 22nd, 2015', 'August 11th, 2014', 'May 24th, 2013',\n",
       "       'August 30th, 2012', 'February 9th, 2012', 'February 1st, 2012',\n",
       "       'November 29th, 2010', 'August 23rd, 2017', 'May 10th, 2017',\n",
       "       'February 17th, 2017', 'July 21st, 2016', 'April 25th, 2016',\n",
       "       'January 15th, 2015', 'February 18th, 2014', 'July 16th, 2013',\n",
       "       'June 26th, 2012', 'May 26th, 2010', 'November 8th, 2016',\n",
       "       'June 15th, 2016', 'May 5th, 2016', 'October 12th, 2015',\n",
       "       'July 14th, 2015', 'July 15th, 2014', 'April 7th, 2014',\n",
       "       'February 25th, 2014', 'February 14th, 2014', 'January 21st, 2014',\n",
       "       'October 3rd, 2013', 'August 29th, 2012', 'May 30th, 2012',\n",
       "       'March 7th, 2017', 'September 20th, 2016', 'August 12th, 2016',\n",
       "       'May 19th, 2016', 'January 12th, 2016', 'June 18th, 2015',\n",
       "       'March 7th, 2014', 'August 2nd, 2013', 'March 29th, 2013',\n",
       "       'March 21st, 2013', 'August 1st, 2012', 'February 23rd, 2012',\n",
       "       'February 22nd, 2012', 'June 14th, 2011', 'February 22nd, 2011',\n",
       "       'January 17th, 2011', 'August 24th, 2017', 'June 20th, 2017',\n",
       "       'June 16th, 2017', 'May 8th, 2017', 'May 2nd, 2016',\n",
       "       'April 5th, 2016', 'March 29th, 2016', 'October 29th, 2015',\n",
       "       'September 29th, 2015', 'July 3rd, 2015', 'October 28th, 2014',\n",
       "       'August 25th, 2014', 'April 12th, 2014', 'March 27th, 2014',\n",
       "       'February 7th, 2014', 'January 31st, 2014', 'June 8th, 2012',\n",
       "       'March 19th, 2012', 'February 17th, 2012', 'May 19th, 2015',\n",
       "       'April 20th, 2015', 'February 19th, 2014', 'July 29th, 2011',\n",
       "       'July 18th, 2016', 'December 28th, 2015', 'July 8th, 2015',\n",
       "       'April 23rd, 2015', 'February 13th, 2015', 'March 15th, 2013',\n",
       "       'October 23rd, 2012', 'May 22nd, 2012', 'May 11th, 2012',\n",
       "       'April 27th, 2012', 'December 2nd, 2011', 'May 12th, 2011',\n",
       "       'February 1st, 2011', 'August 28th, 2017', 'July 7th, 2017',\n",
       "       'June 28th, 2016', 'February 26th, 2016', 'September 7th, 2015',\n",
       "       'July 31st, 2015', 'July 21st, 2015', 'June 11th, 2015',\n",
       "       'August 15th, 2014', 'April 3rd, 2014', 'December 27th, 2013',\n",
       "       'September 13th, 2013', 'March 20th, 2013', 'March 11th, 2013',\n",
       "       'January 22nd, 2013', 'July 20th, 2012', 'March 5th, 2012',\n",
       "       'July 19th, 2011', 'October 13th, 2017', 'June 22nd, 2017',\n",
       "       'February 6th, 2017', 'April 8th, 2016', 'March 25th, 2016',\n",
       "       'January 19th, 2016', 'July 20th, 2015', 'May 26th, 2015',\n",
       "       'March 21st, 2015', 'February 20th, 2015', 'January 20th, 2014',\n",
       "       'May 10th, 2013', 'October 17th, 2017', 'September 19th, 2017',\n",
       "       'September 8th, 2017', 'August 22nd, 2017', 'August 8th, 2017',\n",
       "       'April 28th, 2017', 'April 6th, 2017', 'November 7th, 2014',\n",
       "       'November 4th, 2014', 'February 4th, 2014', 'April 11th, 2012',\n",
       "       'June 2nd, 2016', 'February 25th, 2016', 'November 3rd, 2015',\n",
       "       'December 15th, 2014', 'June 25th, 2014', 'June 13th, 2012',\n",
       "       'November 16th, 2011', 'September 3rd, 2010', 'April 19th, 2017',\n",
       "       'September 15th, 2015', 'February 15th, 2015', 'May 9th, 2014',\n",
       "       'April 18th, 2014', 'December 10th, 2013', 'April 16th, 2013',\n",
       "       'February 27th, 2013', 'September 4th, 2017', 'June 3rd, 2017',\n",
       "       'April 14th, 2014', 'January 14th, 2014', 'May 7th, 2013',\n",
       "       'June 7th, 2012', 'September 27th, 2017', 'January 20th, 2017',\n",
       "       'August 14th, 2014', 'May 8th, 2014', 'December 30th, 2013',\n",
       "       'December 12th, 2013', 'May 31st, 2013', 'September 10th, 2012',\n",
       "       'July 25th, 2012', 'January 31st, 2012', 'December 22nd, 2011',\n",
       "       'September 22nd, 2011', 'February 9th, 2017', 'October 13th, 2016',\n",
       "       'July 15th, 2016', 'May 17th, 2016', 'March 10th, 2015',\n",
       "       'June 10th, 2014', 'October 5th, 2012', 'August 31st, 2016',\n",
       "       'April 15th, 2015', 'May 3rd, 2013', 'September 19th, 2012',\n",
       "       'August 21st, 2012', 'June 9th, 2016', 'October 20th, 2015',\n",
       "       'April 10th, 2014', 'May 29th, 2013', 'August 2nd, 2012',\n",
       "       'January 8th, 2015', 'September 12th, 2014', 'July 23rd, 2012',\n",
       "       'April 18th, 2011', 'November 5th, 2015', 'October 31st, 2014',\n",
       "       'July 22nd, 2014', 'June 20th, 2014', 'April 30th, 2014',\n",
       "       'June 3rd, 2013', 'May 21st, 2013', 'June 4th, 2012',\n",
       "       'October 26th, 2016', 'May 5th, 2015', 'January 6th, 2015',\n",
       "       'July 29th, 2014', 'January 19th, 2017', 'August 2nd, 2016',\n",
       "       'July 17th, 2015', 'June 25th, 2015', 'May 7th, 2015',\n",
       "       'May 16th, 2014', 'April 26th, 2014', 'March 6th, 2013',\n",
       "       'March 2nd, 2013', 'December 21st, 2015', 'October 4th, 2011',\n",
       "       'January 2nd, 2015', 'May 23rd, 2014', 'February 8th, 2012',\n",
       "       'January 19th, 2018', 'February 3rd, 2015', 'November 6th, 2013',\n",
       "       'September 17th, 2015', 'January 7th, 2015',\n",
       "       'September 23rd, 2014', 'August 18th, 2014', 'May 5th, 2014',\n",
       "       'January 25th, 2012', 'September 7th, 2011', 'May 12th, 2017',\n",
       "       'March 17th, 2016', 'October 17th, 2014', 'May 26th, 2014',\n",
       "       'October 7th, 2013', 'November 11th, 2011', 'November 20th, 2015',\n",
       "       'May 22nd, 2015', 'December 16th, 2014', 'November 13th, 2014',\n",
       "       'December 17th, 2014', 'March 4th, 2013', 'March 8th, 2017',\n",
       "       'March 11th, 2015', 'August 20th, 2012', 'July 14th, 2017',\n",
       "       'June 21st, 2017', 'March 28th, 2015', 'March 4th, 2015',\n",
       "       'May 28th, 2014', 'September 14th, 2012', 'September 9th, 2016',\n",
       "       'July 22nd, 2016', 'July 23rd, 2015', 'May 6th, 2015',\n",
       "       'January 26th, 2015', 'December 8th, 2017', 'January 13th, 2015',\n",
       "       'January 25th, 2011', 'May 28th, 2015', 'May 25th, 2015',\n",
       "       'April 11th, 2014', 'November 10th, 2015', 'October 23rd, 2015',\n",
       "       'February 27th, 2015', 'October 23rd, 2014', 'June 5th, 2013',\n",
       "       'March 11th, 2016', 'January 28th, 2014', 'November 17th, 2015',\n",
       "       'April 23rd, 2014', 'April 17th, 2014', 'February 13th, 2013',\n",
       "       'February 3rd, 2016', 'December 26th, 2013\\n',\n",
       "       'January 22nd, 2016', 'June 6th, 2013', 'November 3rd, 2017',\n",
       "       'April 26th, 2016', 'August 27th, 2015', 'March 3rd, 2014',\n",
       "       'January 8th, 2014', 'January 9th, 2013', 'May 9th, 2017',\n",
       "       'August 7th, 2013', 'September 13th, 2012', 'November 29th, 2017',\n",
       "       'June 13th, 2017', 'May 12th, 2014', 'August 25th, 2017',\n",
       "       'April 5th, 2012', 'July 28th, 2014', 'January 23rd, 2014',\n",
       "       'September 23rd, 2013', 'June 27th, 2013', 'January 13th, 2011',\n",
       "       'May 13th, 2014', 'March 31st, 2014', 'January 13th, 2012',\n",
       "       'July 27th, 2017', 'June 30th, 2015', 'April 9th, 2010',\n",
       "       'September 12th, 2012', 'September 11th, 2014',\n",
       "       'January 8th, 2013', 'May 22nd, 2017', 'July 5th, 2013',\n",
       "       'July 16th, 2012', 'February 17th, 2016', 'September 4th, 2014',\n",
       "       'March 19th, 2014', 'February 7th, 2013', 'January 20th, 2015',\n",
       "       'July 18th, 2017', 'May 15th, 2014', 'March 18th, 2014',\n",
       "       'September 5th, 2013', 'April 29th, 2013', 'February 29th, 2016',\n",
       "       'January 29th, 2013', 'January 27th, 2014', 'June 16th, 2015',\n",
       "       'January 16th, 2017', 'January 3rd, 2012', 'May 14th, 2013',\n",
       "       'October 27th, 2017', 'January 6th, 2012', 'January 9th, 2012',\n",
       "       'January 5th, 2012', 'October 31st, 2017', 'July 14th, 2014',\n",
       "       'October 25th, 2017', 'August 17th, 2016', 'August 5th, 2014',\n",
       "       'August 23rd, 2016', 'May 19th, 2014', 'June 20th, 2013',\n",
       "       'December 23rd, 2014'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Grading.Date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51021110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "df2['Grading.Date']=df2['Grading.Date'].apply(parser.parse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75aaaf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0 Country.of.Origin     Altitude         Harvest.Year  \\\n",
      "0              0          ethiopia  2075.000000  2014-05-04 00:00:00   \n",
      "1              1          ethiopia  2075.000000  2014-05-04 00:00:00   \n",
      "3              3          ethiopia  2000.000000  2014-05-04 00:00:00   \n",
      "4              4          ethiopia  2075.000000  2014-05-04 00:00:00   \n",
      "5              5            brazil  1855.490483  2013-05-04 00:00:00   \n",
      "...          ...               ...          ...                  ...   \n",
      "1334        1334           ecuador  1855.490483  2016-05-04 00:00:00   \n",
      "1335        1335           ecuador    40.000000  2016-05-04 00:00:00   \n",
      "1336        1336     united states  1855.490483  2014-05-04 00:00:00   \n",
      "1337        1337             india  1855.490483  2013-05-04 00:00:00   \n",
      "1338        1338           vietnam  1855.490483  2013-05-04 00:00:00   \n",
      "\n",
      "     Grading.Date Processing.Method  Aroma  Flavor  Aftertaste  Acidity  Body  \\\n",
      "0      2015-04-04      Washed / Wet   8.67    8.83        8.67     8.75  8.50   \n",
      "1      2015-04-04      Washed / Wet   8.75    8.67        8.50     8.58  8.42   \n",
      "3      2015-03-26     Natural / Dry   8.17    8.58        8.42     8.42  8.50   \n",
      "4      2015-04-04      Washed / Wet   8.25    8.50        8.25     8.50  8.42   \n",
      "5      2013-09-03     Natural / Dry   8.58    8.42        8.42     8.50  8.25   \n",
      "...           ...               ...    ...     ...         ...      ...   ...   \n",
      "1334   2016-01-19      Washed / Wet   7.75    7.58        7.33     7.58  5.08   \n",
      "1335   2016-01-19      Washed / Wet   7.50    7.67        7.75     7.75  5.17   \n",
      "1336   2014-12-23     Natural / Dry   7.33    7.33        7.17     7.42  7.50   \n",
      "1337   2014-08-25     Natural / Dry   7.42    6.83        6.75     7.17  7.25   \n",
      "1338   2014-08-25     Natural / Dry   6.75    6.67        6.50     6.83  6.92   \n",
      "\n",
      "      Balance  Cupper.Points  Total.Cup.Points  Moisture         Color  \\\n",
      "0        8.42           8.75             90.58      0.12         Green   \n",
      "1        8.42           8.58             89.92      0.12         Green   \n",
      "3        8.25           8.67             89.00      0.11         Green   \n",
      "4        8.33           8.58             88.83      0.12         Green   \n",
      "5        8.33           8.33             88.83      0.11  Bluish-Green   \n",
      "...       ...            ...               ...       ...           ...   \n",
      "1334     7.83           7.83             78.75      0.00    Blue-Green   \n",
      "1335     5.25           8.58             78.08      0.00    Blue-Green   \n",
      "1336     7.17           7.17             77.17      0.00         Green   \n",
      "1337     7.00           6.92             75.08      0.10         Green   \n",
      "1338     6.83           7.92             73.75      0.12          None   \n",
      "\n",
      "     Expiration unit_of_measurement  Defects  \n",
      "0    2016-04-03                   m        0  \n",
      "1    2016-04-03                   m        1  \n",
      "3    2016-03-25                   m        2  \n",
      "4    2016-04-03                   m        2  \n",
      "5    2014-09-03                   m        1  \n",
      "...         ...                 ...      ...  \n",
      "1334 2017-01-18                   m        1  \n",
      "1335 2017-01-18                   m        0  \n",
      "1336 2015-12-23                   m        6  \n",
      "1337 2015-08-25                   m       21  \n",
      "1338 2015-08-25                   m       72  \n",
      "\n",
      "[1292 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "# Assuming df2 is your DataFrame with the column 'Grading.Date'\n",
    "#df2['Grading.Date'] = df2['Grading.Date'].apply(parser.parse)\n",
    "\n",
    "\n",
    "# Print the DataFrame to verify the conversion\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdda3de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1292 entries, 0 to 1338\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   Unnamed: 0           1292 non-null   int64         \n",
      " 1   Country.of.Origin    1292 non-null   object        \n",
      " 2   Altitude             1292 non-null   float64       \n",
      " 3   Harvest.Year         1292 non-null   object        \n",
      " 4   Grading.Date         1292 non-null   datetime64[ns]\n",
      " 5   Processing.Method    1292 non-null   object        \n",
      " 6   Aroma                1292 non-null   float64       \n",
      " 7   Flavor               1292 non-null   float64       \n",
      " 8   Aftertaste           1292 non-null   float64       \n",
      " 9   Acidity              1292 non-null   float64       \n",
      " 10  Body                 1292 non-null   float64       \n",
      " 11  Balance              1292 non-null   float64       \n",
      " 12  Cupper.Points        1292 non-null   float64       \n",
      " 13  Total.Cup.Points     1292 non-null   float64       \n",
      " 14  Moisture             1292 non-null   float64       \n",
      " 15  Color                1292 non-null   object        \n",
      " 16  Expiration           1292 non-null   datetime64[ns]\n",
      " 17  unit_of_measurement  1292 non-null   object        \n",
      " 18  Defects              1292 non-null   int64         \n",
      "dtypes: datetime64[ns](2), float64(10), int64(2), object(5)\n",
      "memory usage: 201.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65ef90fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7727ba62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2014-05-04 00:00:00\n",
       "1       2014-05-04 00:00:00\n",
       "3       2014-05-04 00:00:00\n",
       "4       2014-05-04 00:00:00\n",
       "5       2013-05-04 00:00:00\n",
       "               ...         \n",
       "1334    2016-05-04 00:00:00\n",
       "1335    2016-05-04 00:00:00\n",
       "1336    2014-05-04 00:00:00\n",
       "1337    2013-05-04 00:00:00\n",
       "1338    2013-05-04 00:00:00\n",
       "Name: Harvest.Year, Length: 1292, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Harvest.Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "203032b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Country.of.Origin</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Harvest.Year</th>\n",
       "      <th>Grading.Date</th>\n",
       "      <th>Processing.Method</th>\n",
       "      <th>Aroma</th>\n",
       "      <th>Flavor</th>\n",
       "      <th>Aftertaste</th>\n",
       "      <th>Acidity</th>\n",
       "      <th>Body</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Cupper.Points</th>\n",
       "      <th>Total.Cup.Points</th>\n",
       "      <th>Moisture</th>\n",
       "      <th>Color</th>\n",
       "      <th>Expiration</th>\n",
       "      <th>unit_of_measurement</th>\n",
       "      <th>Defects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, Country.of.Origin, Altitude, Harvest.Year, Grading.Date, Processing.Method, Aroma, Flavor, Aftertaste, Acidity, Body, Balance, Cupper.Points, Total.Cup.Points, Moisture, Color, Expiration, unit_of_measurement, Defects]\n",
       "Index: []"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the column to datetime type with error handling\n",
    "df2['Harvest.Year'] = pd.to_datetime(df2['Harvest.Year'], errors='coerce')\n",
    "\n",
    "# Print rows with out-of-bounds dates\n",
    "df2[df2['Harvest.Year'].isnull()]\n",
    "\n",
    "# Now, you can proceed with the rest of your analysis, keeping in mind that some dates may be missing or converted to NaT (Not a Time).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dfb3456d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df2['Harvest.Year'].dt.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f4b4c83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([374, 493], dtype='int64')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['Harvest.Year'].dt.year>2018].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bd3d3807",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(df2[df2['Harvest.Year'].dt.year>2018].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05112f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01456dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1292 entries, 0 to 1338\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   Unnamed: 0           1292 non-null   int64         \n",
      " 1   Country.of.Origin    1292 non-null   object        \n",
      " 2   Altitude             1292 non-null   float64       \n",
      " 3   Harvest.Year         1291 non-null   datetime64[ns]\n",
      " 4   Grading.Date         1292 non-null   datetime64[ns]\n",
      " 5   Processing.Method    1292 non-null   object        \n",
      " 6   Aroma                1292 non-null   float64       \n",
      " 7   Flavor               1292 non-null   float64       \n",
      " 8   Aftertaste           1292 non-null   float64       \n",
      " 9   Acidity              1292 non-null   float64       \n",
      " 10  Body                 1292 non-null   float64       \n",
      " 11  Balance              1292 non-null   float64       \n",
      " 12  Cupper.Points        1292 non-null   float64       \n",
      " 13  Total.Cup.Points     1292 non-null   float64       \n",
      " 14  Moisture             1292 non-null   float64       \n",
      " 15  Color                1292 non-null   object        \n",
      " 16  Expiration           1292 non-null   datetime64[ns]\n",
      " 17  unit_of_measurement  1292 non-null   object        \n",
      " 18  Defects              1292 non-null   int64         \n",
      "dtypes: datetime64[ns](3), float64(10), int64(2), object(4)\n",
      "memory usage: 234.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b7637dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1289"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(df2['Grading.Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "10a6a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a new CSV file\n",
    "df2.to_csv(\"coffee_CleanNew_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d247cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
